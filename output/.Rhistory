library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
hm_data <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data <- read_csv(urlfile)
hm_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
original_hm,
cleaned_hmï¼Œ
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
predicted_category,
text) %>%
mutate(count = sapply(hm_data$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
#fliter(predicted_category %in% c("affection","exercise","bonding","leisure","achievement","enjoy_the_moment","achievement")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
corpus.list=hm_data[2:(nrow(hm_data)-1), ]
words.pre=hm_data$cleaned_hm[1:(nrow(hm_data)-2)]
words.post=hm_data$cleaned_hm[3:(nrow(hm_data)-1)]
corpus.list$snipets=paste(words.pre, corpus.list$cleaned_hm, words.post, sep=" ")
docs <- tm_map(docs, stripWhitespace)
dtm <- DocumentTermMatrix(Corpus(VectorSource(corpus.list$snipets)))
rowTotals <- apply(dtm , 1, sum)
rowTotals <- apply(dtm , 1, sum)
memory.limit()
hm.list=hm_data[2:(nrow(hm_data)-1), ]
sent.pre=hm_data$cleaned_hm[1:(nrow(hm_data)-2)]
sent.post=hm_data$cleaned_hm[3:(nrow(hm_data)-1)]
hm.list$snipets=paste(sent.pre, hm.list$clean_hm, sent.post, sep=" ")
docs_c <- Corpus(VectorSource(hm.list$snipets))
hlw <- DocumentTermMatrix(docs_c)
rowTotals_c <- apply(hlw , 1, sum)
View(hm_data)
View(hm_data)
>memory.limit()
> memory.limit(size=1800)
> summary(fit)
memory.limit()
memory.limit(size=1800)
summary(fit)
memory.limit()
memory.limit(size=1800)
summary(fit)
memory.limit(size=1800)
memory.limit()
memory.limit(size=1800)
rowTotals_c <- apply(hlw , 1, sum)
memory.limit()
memory.limit(size=1800)
memory.limit(size=18000)
rowTotals_c <- apply(hlw , 1, sum)
memory.limit()
memory.limit(size=18000)
memory.limit(size=20000)
hm.list=hm_data[2:(nrow(hm_data)-1), ]
sent.pre=hm_data$cleaned_hm[1:(nrow(hm_data)-2)]
sent.post=hm_data$cleaned_hm[3:(nrow(hm_data)-1)]
hm.list$snipets=paste(sent.pre, hm.list$clean_hm, sent.post, sep=" ")
docs_c <- Corpus(VectorSource(hm.list$snipets))
hlw <- DocumentTermMatrix(docs_c)
hm.list=hm_data[2:(nrow(hm_data)-1), ]
sent.pre=hm_data$cleaned_hm[1:(nrow(hm_data)-2)]
sent.post=hm_data$cleaned_hm[3:(nrow(hm_data)-1)]
hm.list$snipets=paste(sent.pre, hm.list$clean_hm, sent.post, sep=" ")
docs_c <- Corpus(VectorSource(hm.list$snipets))
hlw <- DocumentTermMatrix(docs_c)
rowTotals_c <- apply(hlw , 1, sum)
hm.list=hm_data[2:(nrow(hm_data)-1), ]
sent.pre=hm_data$cleaned_hm[1:(nrow(hm_data)-2)]
sent.post=hm_data$cleaned_hm[3:(nrow(hm_data)-1)]
hm.list$snipets=paste(sent.pre, hm.list$clean_hm, sent.post, sep=" ")
docs_c <- Corpus(VectorSource(hm.list$snipets))
hlw <- DocumentTermMatrix(docs_c)
hlw  <- hlw[rowTotals_c> 0, ]
rowTotals_c <- apply(hlw , 1, sum)
